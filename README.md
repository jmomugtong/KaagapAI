# MedQuery

<div align="center">

![MedQuery Logo](docs/assets/logo.png)

**Production RAG System for Clinical Documentation**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-009688.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED.svg)](https://www.docker.com/)

</div>

---

## üè• Overview

MedQuery is a production-grade Retrieval-Augmented Generation (RAG) system designed to surface evidence-based clinical answers from medical documentation. Built 100% with open-source models, achieving sub-2 second response times and 95%+ relevance while maintaining zero external API costs.

### Key Features

- üöÄ **Fast Responses**: Query latency p95 < 2 seconds, cached queries < 200ms
- üéØ **High Accuracy**: ROUGE-L score ‚â• 0.60, hallucination rate < 5%
- üîí **HIPAA Compliant**: PII redaction, audit logging, row-level security
- üí∞ **Zero API Cost**: 100% open-source stack (Ollama, sentence-transformers)
- üìä **Full Observability**: Prometheus metrics, Grafana dashboards, OpenTelemetry tracing

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CLIENT LAYER                                ‚îÇ
‚îÇ  Next.js Frontend: Query Interface + Results Display           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ REST API + JWT Authentication
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     API GATEWAY LAYER                           ‚îÇ
‚îÇ  FastAPI Application Server                                    ‚îÇ
‚îÇ  - POST /api/v1/query (rate limited: 10/min per user)          ‚îÇ
‚îÇ  - POST /api/v1/upload (async document ingestion)              ‚îÇ
‚îÇ  - GET /api/v1/evals (evaluation suite execution)              ‚îÇ
‚îÇ  - GET /metrics (Prometheus endpoint)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Celery Queue ‚îÇ       ‚îÇ  RAG Pipeline    ‚îÇ
‚îÇ  - Embedding  ‚îÇ       ‚îÇ  - Chunking      ‚îÇ
‚îÇ  - Indexing   ‚îÇ       ‚îÇ  - Retrieval     ‚îÇ
‚îÇ  - Evaluation ‚îÇ       ‚îÇ  - Reranking     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   DATA LAYER                                    ‚îÇ
‚îÇ  PostgreSQL + pgvector  ‚îÇ  Redis Cache  ‚îÇ  Ollama LLM          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ Quick Start

### Prerequisites

- **Docker** & **Docker Compose** v2.0+
- **Git**
- 8GB+ RAM recommended
- (Optional) NVIDIA GPU for faster LLM inference

### 1. Clone the Repository

```bash
git clone https://github.com/your-org/medquery.git
cd medquery
```

### 2. Environment Setup

```bash
# Copy environment template
cp .env.example .env

# Generate a secure secret key
python -c "import secrets; print(secrets.token_hex(32))"

# Update .env with your values (especially SECRET_KEY, DB_PASSWORD)
```

### 3. Start All Services

```bash
# Start all containers
docker-compose up -d

# Wait for services to initialize (about 30 seconds)
sleep 30

# Check service status
docker-compose ps
```

### 4. Download AI Models

```bash
# Download Mistral model for Ollama (one-time, ~4GB)
docker-compose exec ollama ollama pull mistral

# The embedding model (all-MiniLM-L6-v2) downloads automatically on first use
```

### 5. Initialize Database

```bash
# Run database migrations
docker-compose exec api alembic upgrade head

# (Optional) Seed sample clinical documents
docker-compose exec api python scripts/seed_clinical_docs.py
```

### 6. Verify Installation

```bash
# Check API health
curl http://localhost:8000/health

# Expected response:
# {"status": "healthy", "version": "0.1.0"}
```

### 7. Access Services

| Service | URL | Description |
|---------|-----|-------------|
| API | http://localhost:8000 | FastAPI application |
| API Docs | http://localhost:8000/docs | Swagger UI |
| Grafana | http://localhost:3000 | Monitoring dashboards |
| Prometheus | http://localhost:9090 | Metrics |
| Ollama | http://localhost:11434 | LLM API |

---

## üìñ Usage

### Submit a Query

```bash
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the post-operative pain protocol for knee replacement?",
    "max_results": 5,
    "confidence_threshold": 0.70
  }'
```

### Upload a Document

```bash
curl -X POST http://localhost:8000/api/v1/upload \
  -F "file=@clinical_protocol.pdf" \
  -F "document_type=protocol" \
  -F 'metadata={"department": "orthopedics", "version": "3.2"}'
```

### Run Evaluation Suite

```bash
# Run full evaluation
docker-compose exec api python scripts/run_evals.py

# Check if thresholds are met
docker-compose exec api python scripts/check_thresholds.py
```

---

## üõ†Ô∏è Development

### Local Development Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: .\venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -e ".[dev,test]"

# Install pre-commit hooks
pre-commit install

# Run development server
make dev
```

### Running Tests

```bash
# All tests
make test

# With coverage report
make test-cov

# Unit tests only
make test-unit

# Integration tests
make test-int
```

### Code Quality

```bash
# Run linters
make lint

# Format code
make format

# Type checking
make type-check

# All checks
make check
```

---

## üìÅ Project Structure

```
medquery/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/              # FastAPI routes and middleware
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py     # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py       # Authentication
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ middleware.py # Request/response middleware
‚îÇ   ‚îú‚îÄ‚îÄ rag/              # RAG pipeline components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunker.py    # Document chunking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py  # Embedding generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py  # Hybrid retrieval (BM25 + vector)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reranker.py   # LLM-based reranking
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cache.py      # Caching logic
‚îÇ   ‚îú‚îÄ‚îÄ llm/              # LLM integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ollama_client.py    # Ollama API client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompt_templates.py # Prompt engineering
‚îÇ   ‚îú‚îÄ‚îÄ security/         # Security modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pii_redaction.py   # PII detection & redaction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input_validation.py # Input sanitization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rate_limiter.py    # Rate limiting
‚îÇ   ‚îú‚îÄ‚îÄ db/               # Database layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres.py   # PostgreSQL + pgvector
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py     # SQLAlchemy models
‚îÇ   ‚îú‚îÄ‚îÄ observability/    # Monitoring & logging
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ telemetry.py  # OpenTelemetry setup
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py    # Prometheus metrics
‚îÇ   ‚îî‚îÄ‚îÄ main.py           # Application entry point
‚îú‚îÄ‚îÄ tests/                # Test suite
‚îú‚îÄ‚îÄ scripts/              # Utility scripts
‚îú‚îÄ‚îÄ datasets/             # Evaluation datasets
‚îú‚îÄ‚îÄ k6/                   # Load test scripts
‚îú‚îÄ‚îÄ docker-compose.yml    # Docker services
‚îú‚îÄ‚îÄ Dockerfile            # Container build
‚îú‚îÄ‚îÄ Makefile              # Development commands
‚îú‚îÄ‚îÄ pyproject.toml        # Project configuration
‚îú‚îÄ‚îÄ requirements.txt      # Pinned dependencies
‚îî‚îÄ‚îÄ README.md             # This file
```

---

## üìä Metrics & Monitoring

### Key Metrics

| Metric | Target | Description |
|--------|--------|-------------|
| Query Latency (p95) | < 2s | 95th percentile response time |
| Cache Hit Rate | > 70% | Embedding cache efficiency |
| Hallucination Rate | < 5% | False citation detection |
| ROUGE-L Score | ‚â• 0.60 | Answer relevance |

### Grafana Dashboards

Access Grafana at http://localhost:3000 (default: admin/admin)

- **Query Performance**: Latency percentiles, throughput
- **Cache Analytics**: Hit rates, memory usage
- **Quality Metrics**: Hallucination rate, confidence scores
- **System Health**: Error rates, resource utilization

---

## üîß Configuration

### Environment Variables

See [.env.example](.env.example) for all available configuration options.

Key variables:

| Variable | Description | Default |
|----------|-------------|---------|
| `SECRET_KEY` | JWT signing key | (generate) |
| `DATABASE_URL` | PostgreSQL connection | postgresql+asyncpg://... |
| `REDIS_URL` | Redis connection | redis://redis:6379/0 |
| `OLLAMA_MODEL` | LLM model name | mistral |
| `RATE_LIMIT_PER_MINUTE` | API rate limit | 10 |

---

## üß™ Evaluation

The evaluation framework validates system quality:

```bash
# Run evaluation suite
python scripts/run_evals.py

# Output:
# ‚úÖ ROUGE-L: 0.68 (threshold: 0.60)
# ‚úÖ Hallucination Rate: 2% (threshold: 5%)
# ‚úÖ Retrieval Recall: 94% (threshold: 90%)
# 
# PASSED: All metrics within thresholds
```

### Evaluation Dataset

Located at `datasets/clinical_qa_50.json`:
- 50 clinical Q&A pairs
- Ground truth answers from clinical experts
- Multi-hop and single-document queries

---

## üîí Security

### HIPAA Compliance

- **PII Redaction**: Automatic detection of patient names, MRNs, DOBs
- **Audit Logging**: All queries logged with user context
- **Row-Level Security**: Hospital data isolation in PostgreSQL
- **Encryption**: TLS 1.3 in transit, AES-256 at rest

### Authentication

- OAuth2 + JWT tokens
- Rate limiting per user (10 req/min)
- Input validation and sanitization

---

## üìù API Documentation

Full API documentation available at:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Main Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/query` | Submit clinical query |
| POST | `/api/v1/upload` | Upload document |
| GET | `/api/v1/jobs/{id}` | Check job status |
| GET | `/api/v1/evals` | Run evaluation |
| GET | `/health` | Health check |
| GET | `/metrics` | Prometheus metrics |

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details.

---

## üìÑ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

---

## üôè Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [Ollama](https://ollama.ai/) - Local LLM inference
- [sentence-transformers](https://www.sbert.net/) - Embedding models
- [pgvector](https://github.com/pgvector/pgvector) - Vector similarity search
- [LangChain](https://python.langchain.com/) - Document processing

---

<div align="center">

**Built with ‚ù§Ô∏è for healthcare professionals**

</div>
